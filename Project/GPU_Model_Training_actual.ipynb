{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, scale_factor):\n",
    "        upsample_block_num = int(math.log(scale_factor, 2))\n",
    "\n",
    "        super(Generator, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.block2 = ResidualBlock(64)\n",
    "        self.block3 = ResidualBlock(64)\n",
    "        self.block4 = ResidualBlock(64)\n",
    "        self.block5 = ResidualBlock(64)\n",
    "        self.block6 = ResidualBlock(64)\n",
    "        self.block7 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        block8 = [UpsampleBLock(64, 2) for _ in range(upsample_block_num)]\n",
    "        block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n",
    "        self.block8 = nn.Sequential(*block8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        block1 = self.block1(x)\n",
    "        block2 = self.block2(block1)\n",
    "        block3 = self.block3(block2)\n",
    "        block4 = self.block4(block3)\n",
    "        block5 = self.block5(block4)\n",
    "        block6 = self.block6(block5)\n",
    "        block7 = self.block7(block6)\n",
    "        block8 = self.block8(block1 + block7)\n",
    "\n",
    "        return (torch.tanh(block8) + 1) / 2\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(512, 1024, kernel_size=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(1024, 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        return torch.sigmoid(self.net(x).view(batch_size))\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.conv1(x)\n",
    "        residual = self.bn1(residual)\n",
    "        residual = self.prelu(residual)\n",
    "        residual = self.conv2(residual)\n",
    "        residual = self.bn2(residual)\n",
    "\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class UpsampleBLock(nn.Module):\n",
    "    def __init__(self, in_channels, up_scale):\n",
    "        super(UpsampleBLock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        x = self.prelu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
    "\n",
    "\n",
    "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
    "    return crop_size - (crop_size % upscale_factor)\n",
    "\n",
    "\n",
    "def train_hr_transform(crop_size):\n",
    "    return Compose([\n",
    "        RandomCrop(crop_size),\n",
    "        ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def train_lr_transform(crop_size, upscale_factor):\n",
    "    return Compose([\n",
    "        ToPILImage(),\n",
    "        Resize(crop_size // upscale_factor, interpolation=Image.BICUBIC),\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "def display_transform():\n",
    "    return Compose([\n",
    "        ToPILImage(),\n",
    "        Resize(400),\n",
    "        CenterCrop(400),\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "class TrainDatasetFromFolder(Dataset):\n",
    "    def __init__(self, dataset_dir, crop_size, upscale_factor):\n",
    "        super(TrainDatasetFromFolder, self).__init__()\n",
    "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
    "        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n",
    "        self.hr_transform = train_hr_transform(crop_size)\n",
    "        self.lr_transform = train_lr_transform(crop_size, upscale_factor)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hr_image = self.hr_transform(Image.open(self.image_filenames[index]))\n",
    "        lr_image = self.lr_transform(hr_image)\n",
    "        return lr_image, hr_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "\n",
    "class ValDatasetFromFolder(Dataset):\n",
    "    def __init__(self, dataset_dir, upscale_factor):\n",
    "        super(ValDatasetFromFolder, self).__init__()\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hr_image = Image.open(self.image_filenames[index])\n",
    "        w, h = hr_image.size\n",
    "        crop_size = calculate_valid_crop_size(min(w, h), self.upscale_factor)\n",
    "        lr_scale = Resize(crop_size // self.upscale_factor, interpolation=Image.BICUBIC)\n",
    "        hr_scale = Resize(crop_size, interpolation=Image.BICUBIC)\n",
    "        hr_image = CenterCrop(crop_size)(hr_image)\n",
    "        lr_image = lr_scale(hr_image)\n",
    "        hr_restore_img = hr_scale(lr_image)\n",
    "        return ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.vgg import vgg16\n",
    "\n",
    "\n",
    "class GeneratorLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorLoss, self).__init__()\n",
    "        vgg = vgg16(pretrained=True)\n",
    "        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
    "        for param in loss_network.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.loss_network = loss_network\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.tv_loss = TVLoss()\n",
    "\n",
    "    def forward(self, out_labels, out_images, target_images):\n",
    "        # Adversarial Loss\n",
    "        adversarial_loss = torch.mean(1 - out_labels)\n",
    "        # Perception Loss\n",
    "        perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
    "        # Image Loss\n",
    "        image_loss = self.mse_loss(out_images, target_images)\n",
    "        # TV Loss\n",
    "        tv_loss = self.tv_loss(out_images)\n",
    "        return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n",
    "\n",
    "\n",
    "class TVLoss(nn.Module):\n",
    "    def __init__(self, tv_loss_weight=1):\n",
    "        super(TVLoss, self).__init__()\n",
    "        self.tv_loss_weight = tv_loss_weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size()[0]\n",
    "        h_x = x.size()[2]\n",
    "        w_x = x.size()[3]\n",
    "        count_h = self.tensor_size(x[:, :, 1:, :])\n",
    "        count_w = self.tensor_size(x[:, :, :, 1:])\n",
    "        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()\n",
    "        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()\n",
    "        return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def tensor_size(t):\n",
    "        return t.size()[1] * t.size()[2] * t.size()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from math import exp\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "\n",
    "def ssim(img1, img2, window_size = 11, size_average = True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    \n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from math import log10\n",
    "\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.utils as utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pytorch_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_SIZE = 88\n",
    "UPSCALE_FACTOR = 8\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TrainDatasetFromFolder('Data/Data/Train', crop_size=CROP_SIZE, upscale_factor=UPSCALE_FACTOR)\n",
    "train_loader = DataLoader(dataset=train_set, num_workers=4, batch_size=128, shuffle=True)\n",
    "val_set = ValDatasetFromFolder('Data/Data/Validation', upscale_factor=UPSCALE_FACTOR)\n",
    "val_loader = DataLoader(dataset=val_set, num_workers=4, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# generator parameters:', 881932)\n",
      "('# discriminator parameters:', 5215425)\n"
     ]
    }
   ],
   "source": [
    "netG = Generator(UPSCALE_FACTOR)\n",
    "print('# generator parameters:', sum(param.numel() for param in netG.parameters()))\n",
    "netD = Discriminator()\n",
    "print('# discriminator parameters:', sum(param.numel() for param in netD.parameters()))\n",
    "generator_criterion = GeneratorLoss()\n",
    "optimizerG = optim.Adam(netG.parameters())\n",
    "optimizerD = optim.Adam(netD.parameters())\n",
    "results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/10] Loss_D: 0.8003 Loss_G: 0.0224 D(x): 0.3105 D(G(z)): 0.0939: 100%|██████████| 131/131 [06:30<00:00,  2.98s/it]\n",
      "[converting LR images to SR images] PSNR: 19.8447 dB SSIM: 0.5134: 100%|██████████| 425/425 [00:38<00:00, 10.98it/s]\n",
      "[2/10] Loss_D: 0.9653 Loss_G: 0.0149 D(x): 0.4002 D(G(z)): 0.3516: 100%|██████████| 131/131 [06:31<00:00,  2.99s/it]\n",
      "[converting LR images to SR images] PSNR: 19.4397 dB SSIM: 0.5194: 100%|██████████| 425/425 [00:39<00:00, 10.83it/s]\n",
      "[3/10] Loss_D: 0.8797 Loss_G: 0.0136 D(x): 0.6477 D(G(z)): 0.5204: 100%|██████████| 131/131 [06:28<00:00,  2.96s/it]\n",
      "[converting LR images to SR images] PSNR: 19.4534 dB SSIM: 0.5378: 100%|██████████| 425/425 [00:39<00:00, 10.71it/s]\n",
      "[4/10] Loss_D: 1.0087 Loss_G: 0.0128 D(x): 0.6200 D(G(z)): 0.6273: 100%|██████████| 131/131 [06:28<00:00,  2.97s/it]\n",
      "[converting LR images to SR images] PSNR: 20.0734 dB SSIM: 0.5371: 100%|██████████| 425/425 [00:39<00:00, 10.81it/s]\n",
      "[5/10] Loss_D: 1.0055 Loss_G: 0.0127 D(x): 0.6512 D(G(z)): 0.6559: 100%|██████████| 131/131 [06:28<00:00,  2.97s/it]\n",
      "[converting LR images to SR images] PSNR: 20.3726 dB SSIM: 0.5545: 100%|██████████| 425/425 [00:39<00:00, 10.68it/s]\n",
      "[saving training results]: 100%|██████████| 85/85 [01:41<00:00,  1.20s/it]\n",
      "[6/10] Loss_D: 1.0022 Loss_G: 0.0123 D(x): 0.7647 D(G(z)): 0.7664: 100%|██████████| 131/131 [06:31<00:00,  2.99s/it]\n",
      "[converting LR images to SR images] PSNR: 21.0508 dB SSIM: 0.5538: 100%|██████████| 425/425 [00:39<00:00, 10.79it/s]\n",
      "[7/10] Loss_D: 0.9998 Loss_G: 0.0119 D(x): 0.9897 D(G(z)): 0.9907: 100%|██████████| 131/131 [06:27<00:00,  2.96s/it]\n",
      "[converting LR images to SR images] PSNR: 20.8935 dB SSIM: 0.5597: 100%|██████████| 425/425 [00:39<00:00, 10.80it/s]\n",
      "[8/10] Loss_D: 1.0000 Loss_G: 0.0116 D(x): 0.9999 D(G(z)): 0.9999: 100%|██████████| 131/131 [06:28<00:00,  2.97s/it]\n",
      "[converting LR images to SR images] PSNR: 21.0553 dB SSIM: 0.5618: 100%|██████████| 425/425 [00:39<00:00, 10.85it/s]\n",
      "[9/10] Loss_D: 1.0000 Loss_G: 0.0116 D(x): 0.9998 D(G(z)): 0.9998: 100%|██████████| 131/131 [06:29<00:00,  2.97s/it]\n",
      "[converting LR images to SR images] PSNR: 19.9070 dB SSIM: 0.5542: 100%|██████████| 425/425 [00:39<00:00, 10.77it/s]\n",
      "[10/10] Loss_D: 1.0000 Loss_G: 0.0117 D(x): 0.9994 D(G(z)): 0.9994: 100%|██████████| 131/131 [06:31<00:00,  2.99s/it]\n",
      "[converting LR images to SR images] PSNR: 20.9377 dB SSIM: 0.5601: 100%|██████████| 425/425 [00:39<00:00, 10.89it/s]\n",
      "[saving training results]: 100%|██████████| 85/85 [01:42<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    netG.cuda()\n",
    "    netD.cuda()\n",
    "    generator_criterion.cuda()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_bar = tqdm(train_loader)\n",
    "    running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
    "\n",
    "    netG.train()\n",
    "    netD.train()\n",
    "    for data, target in train_bar:\n",
    "        g_update_first = True\n",
    "        batch_size = data.size(0)\n",
    "        running_results['batch_sizes'] += batch_size\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        real_img = Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            real_img = real_img.cuda()\n",
    "        z = Variable(data)\n",
    "        if torch.cuda.is_available():\n",
    "            z = z.cuda()\n",
    "        fake_img = netG(z)\n",
    "\n",
    "        netD.zero_grad()\n",
    "        real_out = netD(real_img).mean()\n",
    "        fake_out = netD(fake_img).mean()\n",
    "        d_loss = 1 - real_out + fake_out\n",
    "        d_loss.backward(retain_graph=True)\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
    "        g_loss.backward()\n",
    "\n",
    "        fake_img = netG(z)\n",
    "        fake_out = netD(fake_img).mean()\n",
    "\n",
    "\n",
    "        optimizerG.step()\n",
    "\n",
    "        # loss for current batch before optimization \n",
    "        running_results['g_loss'] += g_loss.item() * batch_size\n",
    "        running_results['d_loss'] += d_loss.item() * batch_size\n",
    "        running_results['d_score'] += real_out.item() * batch_size\n",
    "        running_results['g_score'] += fake_out.item() * batch_size\n",
    "\n",
    "        train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' % (\n",
    "            epoch, NUM_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n",
    "            running_results['g_loss'] / running_results['batch_sizes'],\n",
    "            running_results['d_score'] / running_results['batch_sizes'],\n",
    "            running_results['g_score'] / running_results['batch_sizes']))\n",
    "\n",
    "    netG.eval()\n",
    "    out_path = 'training_results/SRF_' + str(UPSCALE_FACTOR) + '/'\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader)\n",
    "        valing_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n",
    "        val_images = []\n",
    "        for val_lr, val_hr_restore, val_hr in val_bar:\n",
    "            batch_size = val_lr.size(0)\n",
    "            valing_results['batch_sizes'] += batch_size\n",
    "            lr = val_lr\n",
    "            hr = val_hr\n",
    "            if torch.cuda.is_available():\n",
    "                lr = lr.cuda()\n",
    "                hr = hr.cuda()\n",
    "            sr = netG(lr)\n",
    "\n",
    "            batch_mse = ((sr - hr) ** 2).data.mean()\n",
    "            valing_results['mse'] += batch_mse * batch_size\n",
    "            batch_ssim = ssim(sr, hr).item()\n",
    "            valing_results['ssims'] += batch_ssim * batch_size\n",
    "            valing_results['psnr'] = 10 * log10(1 / (valing_results['mse'] / valing_results['batch_sizes']))\n",
    "            valing_results['ssim'] = valing_results['ssims'] / valing_results['batch_sizes']\n",
    "            val_bar.set_description(\n",
    "                desc='[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f' % (\n",
    "                    valing_results['psnr'], valing_results['ssim']))\n",
    "            val_images.extend(\n",
    "                [display_transform()(val_hr_restore.squeeze(0)), display_transform()(hr.data.cpu().squeeze(0)),\n",
    "                 display_transform()(sr.data.cpu().squeeze(0))])\n",
    "        if epoch % 5 == 0 and epoch != 0:\n",
    "            val_images = torch.stack(val_images)\n",
    "            val_images = torch.chunk(val_images, val_images.size(0) // 15)\n",
    "            val_save_bar = tqdm(val_images, desc='[saving training results]')\n",
    "            index = 1\n",
    "            for image in val_save_bar:\n",
    "                image = utils.make_grid(image, nrow=3, padding=5)\n",
    "                utils.save_image(image, out_path + 'epoch_%d_index_%d.png' % (epoch, index), padding=5)\n",
    "                index += 1\n",
    "    if epoch % 5 == 0 and epoch != 0:\n",
    "        # save model parameters\n",
    "        torch.save(netG.state_dict(), 'epochs/netG_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
    "        torch.save(netD.state_dict(), 'epochs/netD_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
    "    # save loss\\scores\\psnr\\ssim\n",
    "    results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n",
    "    results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n",
    "    results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n",
    "    results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])\n",
    "    results['psnr'].append(valing_results['psnr'])\n",
    "    results['ssim'].append(valing_results['ssim'])\n",
    "\n",
    "    if epoch % 5 == 0 and epoch != 0:\n",
    "        out_path = 'statistics/'\n",
    "        data_frame = pd.DataFrame(\n",
    "            data={'Loss_D': results['d_loss'], 'Loss_G': results['g_loss'], 'Score_D': results['d_score'],\n",
    "                  'Score_G': results['g_score'], 'PSNR': results['psnr'], 'SSIM': results['ssim']},\n",
    "            index=range(1, epoch + 1))\n",
    "        data_frame.to_csv(out_path + 'srf_' + str(UPSCALE_FACTOR) + '_train_results.csv', index_label='Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
